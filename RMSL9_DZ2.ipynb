{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUTlyxOKaA4AQbdjSILvi8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solobala/ABD26/blob/main/RMSL9_DZ2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Домашнее задание по теме «Рекомендации на основе содержания»\n",
        "Пакет SURPRISE:\n",
        "\n",
        "используйте данные MovieLens 1M,\n",
        "можно использовать любые модели из пакета,\n",
        "получите RMSE на тестовом сете 0,87 и ниже.\n",
        "\n",
        "* Загружаем данные и собираем датасет(фильм-рейтинг)\n",
        "* Используем средства SURPRISE для перевода pandas датафрейма в нужный формат\n",
        "* Отбираем алгоритм/алгоритмы из SURPRISE, которые будем обучать\n",
        "* В процессе обучения выполняем проверку на 5 фолдах, оцениваем RMSE\n",
        "* Отбираем лучший алгоритм, при необходимости тьюним его"
      ],
      "metadata": {
        "id": "2tcvh3pKQiJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Загрузка данных и импорт библиотек"
      ],
      "metadata": {
        "id": "9Nb8KcXqRH6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://surpriselib.com/\n",
        "\n",
        "Алгоритмы https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html"
      ],
      "metadata": {
        "id": "juOdpe-D-YYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise # prediction algorithms available for recommendation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeNmn__c-Ul_",
        "outputId": "878a9b3f-4255-4553-fd88-cd6e1be1e47a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.25.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3097650 sha256=75e31a5220ced27d4e8f2fb3740a113874a1f8e2c5c5a245edddcce134892d46\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DLoggrtXQaaC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from surprise import Dataset, Trainset\n",
        "from surprise.accuracy import rmse\n",
        "from surprise.similarities import cosine, msd, pearson, pearson_baseline\n",
        "from surprise import Reader\n",
        "from surprise.prediction_algorithms.algo_base import AlgoBase\n",
        "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
        "from surprise.prediction_algorithms.knns import KNNWithMeans,\\\n",
        "KNNWithZScore, KNNBaseline\n",
        "from surprise.prediction_algorithms.matrix_factorization import SVD, SVDpp, NMF\n",
        "from surprise.prediction_algorithms.slope_one import SlopeOne\n",
        "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection.split import KFold\n",
        "# from surprise.model_selection import PredefinedKFold\n",
        "from surprise.model_selection.validation import cross_validate\n",
        "from surprise.model_selection.search import GridSearchCV\n",
        "# from surprise.prediction_algorithms.predictions import Prediction, PredictionImpossible\n",
        "from surprise import accuracy\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Пользовательские функции"
      ],
      "metadata": {
        "id": "hnvpLPS9aTr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset() -> Dataset:\n",
        "  \"\"\"\n",
        "  Prepare dataset for Surprise\n",
        "  \"\"\"\n",
        "  # load dataset\n",
        "  !wget  \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"   # Качаем архив выбранного датасета\n",
        "  # unzip data from zip\n",
        "  !unzip ml-latest-small.zip\n",
        "  # read tables\n",
        "  movies = pd.read_csv('/content/ml-latest-small/movies.csv')\n",
        "  ratings = pd.read_csv('/content/ml-latest-small/ratings.csv')\n",
        "  ratings.drop(columns=['timestamp'], inplace=True)\n",
        "  # join tables\n",
        "  df = ratings.join(movies.set_index('movieId'), on='movieId', how='left')\n",
        "  dataset = pd.DataFrame({\n",
        "    'uid': df.userId,\n",
        "    'iid': df.title,\n",
        "    'rating': df.rating\n",
        "})\n",
        "  min = dataset.rating.min()\n",
        "  max = dataset.rating.max()\n",
        "  reader = Reader(rating_scale=(min, max))\n",
        "  data = Dataset.load_from_df(dataset, reader)\n",
        "  return data"
      ],
      "metadata": {
        "id": "g59i-QMnSadf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_algo(algo_name) -> AlgoBase():\n",
        "  \"\"\"\n",
        "  Make a dictionary with surprise models\n",
        "  Args:\n",
        "    algo_name:str - a name of surprise model\n",
        "  Return:\n",
        "    algos[algo_name]: AlgoBase - choosed model\n",
        "  \"\"\"\n",
        "  algos = dict()\n",
        "  algos['BaselineOnly'] = BaselineOnly()\n",
        "  algos['KNNWithMeans'] = KNNWithMeans()\n",
        "  algos['KNNWithZScore'] = KNNWithZScore()\n",
        "  algos['KNNBaseline'] = KNNBaseline()\n",
        "  algos['SVD'] = SVD()\n",
        "  algos['SVDpp'] = SVDpp()\n",
        "  algos['NMF'] = NMF()\n",
        "  algos['SlopeOne'] = SlopeOne()\n",
        "  algos['CoClustering'] = CoClustering()\n",
        "  return algos[algo_name]"
      ],
      "metadata": {
        "id": "ngV6iBcBBesR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_features(data: Dataset, split_ratio: float, random_seed: int) -> tuple[Trainset, Trainset, Trainset]:\n",
        "  \"\"\"Make datasets for fit, predict, cross_validate model\n",
        "  Args:\n",
        "    data: Dataset - whole dataset\n",
        "  Return:\n",
        "    trainset: Trainset,\n",
        "    testset: Trainset\n",
        "    traintestfull: Trainset\n",
        "  \"\"\"\n",
        "  trainset, testset = train_test_split(data, test_size=split_ratio, random_state=random_seed)\n",
        "  traintestfull = data.build_full_trainset()\n",
        "  return  trainset, testset, traintestfull"
      ],
      "metadata": {
        "id": "PVgdODYbU8iL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model( trainset: Trainset, algo_name: str) -> np.float64:\n",
        "  \"\"\"\n",
        "  Get algoritm by its name,\n",
        "  fit model, predict on test dataset\n",
        "  & return rmse\n",
        "  Will be used for primary algoritm's selecton\n",
        "  Args:\n",
        "    trainset: Trainset - train dataset\n",
        "    algo_name: str\n",
        "  Return: rmse: np.float64\n",
        "  \"\"\"\n",
        "  # get algoritm\n",
        "  algo = get_algo(algo_name)\n",
        "  # fit algoritm\n",
        "  algo.fit(trainset)\n",
        "  predictions = algo.test(testset)\n",
        "  return accuracy.rmse(predictions, verbose=False)\n"
      ],
      "metadata": {
        "id": "OIL_IUrGUKDW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(data, algo_name):\n",
        "  algo = get_algo(algo_name)\n",
        "  results = cross_validate(algo=algo, data=data, measures=['RMSE'], cv=5, return_train_measures=True)\n",
        "  return results['test_rmse'].mean()"
      ],
      "metadata": {
        "id": "_t1sp424lo1g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = make_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7CglY4I-MCz",
        "outputId": "a20080b7-0271-4d59-d968-7cfbf5f30efd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-06 11:01:20--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-07-06 11:01:20 (8.12 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset, trainsetfull = build_features(data, 0.15, 42)"
      ],
      "metadata": {
        "id": "_8evIdM5_k9_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to save list of raw & inner item's id's\n",
        "trainset_iids = list(trainset.all_items()) # It is moviesId\n",
        "iid_converter = lambda x: trainset.to_raw_iid(x)\n",
        "trainset_raw_iids = list(map(iid_converter, trainset_iids)) # it is movies titles"
      ],
      "metadata": {
        "id": "X6J8EOilWNtU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algos = [\n",
        " 'BaselineOnly',\n",
        " 'KNNWithMeans',\n",
        " 'KNNWithZScore',\n",
        " 'KNNBaseline',\n",
        "  'SVD',\n",
        " 'SVDpp',\n",
        "'NMF',\n",
        " 'SlopeOne',\n",
        " 'CoClustering'\n",
        "]"
      ],
      "metadata": {
        "id": "mNgY6_hOo4QQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = dict()\n",
        "for algo in algos:\n",
        "  results[algo] = train_model(trainset, algo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m37ZycwZoa-A",
        "outputId": "c25e7188-7e77-4600-cda1-9fa04f2ad5fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nykw9Gq4hdxa",
        "outputId": "2a815e40-b7e7-4c16-fd51-95df021e7c32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BaselineOnly': 0.8824900429621578,\n",
              " 'KNNWithMeans': 0.9041790317046055,\n",
              " 'KNNWithZScore': 0.9024747395939957,\n",
              " 'KNNBaseline': 0.8828909395729079,\n",
              " 'SVD': 0.8810904905144165,\n",
              " 'SVDpp': 0.8737186435529336,\n",
              " 'NMF': 0.9299851823491933,\n",
              " 'SlopeOne': 0.9086010702465205,\n",
              " 'CoClustering': 0.9527419328431517}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С параметрами по умолчанию лучший результат на текстовой выборке - у SVDpp. Далее будем работать с этим алгоритмом"
      ],
      "metadata": {
        "id": "NO3qhTd4lOs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "algo=SVDpp()\n",
        "cv_results = cross_validate(algo=algo, data=data, measures=['RMSE'], cv=5, return_train_measures=True, verbose=False)\n"
      ],
      "metadata": {
        "id": "8VBIuSOhoHXS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results['test_rmse'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C5XEy-E-bij",
        "outputId": "f093e288-b498-4641-e026-2cf37b9952d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8614040035255691"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для алгоритма SVDpp уже достигнут требуемый результат при выполнении кросс-валидации на 5 фолдах: 0.8616685463384428 < 0.87. Оценим rmsе по фолдам"
      ],
      "metadata": {
        "id": "YU_PEDvsD7Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "\n",
        "algo = SVDpp()\n",
        "\n",
        "for trainset, testset in kf.split(data):\n",
        "\n",
        "    # train and test algorithm.\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # Compute and print Root Mean Squared Error\n",
        "    accuracy.rmse(predictions, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUYFoh1pEKiF",
        "outputId": "732695f2-d4a7-4bb8-8fcb-768ce559f2d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8628\n",
            "RMSE: 0.8647\n",
            "RMSE: 0.8563\n",
            "RMSE: 0.8574\n",
            "RMSE: 0.8637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На каждом фолде RMSE меньше заявленного порога. Попробуем еще улучшить модель и выполним настройку гиперпараметров"
      ],
      "metadata": {
        "id": "sVmJ3k5kE0nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\"n_epochs\": [10,20], \"lr_all\": [0.005, 0.01], \"reg_all\": [0.4, 0.5]}\n",
        "gs = GridSearchCV(SVDpp, param_grid, measures=[\"rmse\"], cv=5)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score[\"rmse\"])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params[\"rmse\"])"
      ],
      "metadata": {
        "id": "sX7zxHjGEz3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Рекомендации"
      ],
      "metadata": {
        "id": "h2l3uFJD6--f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendation(uid, model, dataset, thresh=4.5, amount=5):\n",
        "    all_titles = list(dataset['iid'].values)\n",
        "    users_seen_titles = dataset[dataset['uid'] == uid]['iid']\n",
        "    titles = np.array(list(set(all_titles) - set(users_seen_titles)))\n",
        "\n",
        "    np.random.shuffle(titles)\n",
        "\n",
        "    rec_list = []\n",
        "    for title in titles:\n",
        "        review_prediction = model.predict(uid=uid, iid=title)\n",
        "        rating = review_prediction.est\n",
        "\n",
        "        if rating >= thresh:\n",
        "            rec_list.append((title, round(rating, 2)))\n",
        "\n",
        "            if len(rec_list) >= amount:\n",
        "                return rec_list"
      ],
      "metadata": {
        "id": "0FbE4M0agYMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = SVDpp(n_epochs= gs.best_params[\"n_epochs\"],\n",
        "             lr_all=gs.best_params[\"lr_all\"],\n",
        "             reg_all=gs.best_params[\"reg_all\"])\n",
        "generate_recommendation(2, algo, data, thresh=4.8)"
      ],
      "metadata": {
        "id": "MTSQjE0n7Gxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}